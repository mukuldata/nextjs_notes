# Using Vercel AI SDK with Next.js

### **Table of Contents**

1. **Introduction to Vercel AI SDK**
2. **Why Use Vercel AI SDK with Next.js?**
3. **Installing Vercel AI SDK in Next.js**
4. **Using Vercel AI SDK for AI Models (Example with OpenAI API)**
5. **Building an AI Chatbot in Next.js with Vercel AI SDK**
6. **Streaming AI Responses with Vercel AI SDK**
7. **Best Practices for Using Vercel AI SDK**
8. **Conclusion**

***

### **1. Introduction to Vercel AI SDK**

ðŸ”¹ **Vercel AI SDK** is a tool that helps developers integrate **AI models** like OpenAIâ€™s GPT, other LLMs into their **Next.js applications** easily.\
ðŸ”¹ It **simplifies API calls**, enables **real-time streaming**, and works well with **Server Actions & Edge Functions** in Next.js.

ðŸ“Œ **What Can You Do with It?**\
âœ” Create AI-powered **chatbots**\
âœ” Generate **text, images, or summaries** using AI\
âœ” Stream AI responses progressively

***

### **2. Why Use Vercel AI SDK with Next.js?**

ðŸš€ **Benefits of using Vercel AI SDK:**\
âœ” **Easy API integration** â€“ No need for complex HTTP requests.\
âœ” **Supports streaming** â€“ AI responses appear **word by word** like ChatGPT.\
âœ” **Works with Server Actions** â€“ Optimized for Next.js **Server Components**.\
âœ” **Edge deployment ready** â€“ Fast execution with **Vercel Edge Functions**.

âœ… **Use Cases:**

* AI-powered **chatbots**
* Text **summarization**
* AI-based **code generation**
* **Q\&A systems** with real-time responses

***

### **3. Installing Vercel AI SDK in Next.js**

ðŸ“Œ **First, install the SDK in your Next.js project:**

```sh
npm install ai
```

or using Yarn:

```sh
yarn add ai
```

***

### **4. Using Vercel AI SDK for AI Models (Example with OpenAI API)**

ðŸ“Œ **Let's connect OpenAIâ€™s GPT model to Next.js using Vercel AI SDK.**

#### **Step 1: Set Up API Route for AI Requests**

ðŸ”¹ We create an API route that **sends user input to OpenAI and gets AI-generated responses**.

ðŸ“Œ **Create `app/api/chat/route.ts` in your Next.js project:**

```ts
import { OpenAIStream, StreamingTextResponse } from 'ai';
import OpenAI from 'openai';

// Initialize OpenAI API
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY, // Set API Key in .env file
});

export async function POST(req: Request) {
  const { prompt } = await req.json(); // Get user input

  const response = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages: [{ role: "user", content: prompt }],
    stream: true, // Enable streaming for real-time responses
  });

  // Convert OpenAI response into a readable stream
  const stream = OpenAIStream(response);
  return new StreamingTextResponse(stream);
}
```

âœ… **What Happens Here?**\
âœ” The API **receives user input (`prompt`)**.\
âœ” Sends input to **OpenAIâ€™s GPT-3.5-turbo** model.\
âœ” Uses **streaming** to send responses back word by word.\
âœ” Returns AI-generated text **as a live stream**.

***

### **5. Building an AI Chatbot in Next.js with Vercel AI SDK**

ðŸ“Œ **Now, create a simple chatbot UI that connects with our AI API.**

#### **Step 1: Create Chat Component**

ðŸ”¹ This component will **send messages to the AI API** and **display responses**.

ðŸ“Œ **Create `app/chat/page.tsx`**

```tsx
"use client";

import { useChat } from "ai/react";

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit } = useChat({
    api: "/api/chat",
  });

  return (
    <div className="chat-container">
      <h1>AI Chatbot</h1>
      <div className="messages">
        {messages.map((m, index) => (
          <p key={index} className={m.role === "user" ? "user" : "ai"}>
            <strong>{m.role}:</strong> {m.content}
          </p>
        ))}
      </div>
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="Ask me anything..."
        />
        <button type="submit">Send</button>
      </form>
    </div>
  );
}
```

âœ… **How It Works:**\
âœ” **useChat hook** simplifies AI interactions.\
âœ” Messages **update in real-time** as AI responds.\
âœ” **User input** is sent to our API (`/api/chat`).\
âœ” AI-generated responses **appear progressively**.

***

### **6. Streaming AI Responses with Vercel AI SDK**

ðŸ“Œ **Streaming improves user experience by displaying AI responses as they are generated (like ChatGPT).**

#### **Modify API Route to Enable Streaming**

ðŸ”¹ If not already done, make sure **streaming is enabled** in `app/api/chat/route.ts`:

```ts
const response = await openai.chat.completions.create({
  model: "gpt-3.5-turbo",
  messages: [{ role: "user", content: prompt }],
  stream: true, // Enables live streaming
});
```

âœ… **Now, AI responses will be shown word by word instead of waiting for the full answer.**

***

### **7. Best Practices for Using Vercel AI SDK**

ðŸš€ **Follow these tips for the best performance:**\
âœ” **Use Edge Functions** for faster AI responses.\
âœ” **Enable Streaming** to avoid long wait times.\
âœ” **Store API keys securely** in `.env.local` file.\
âœ” **Use `useChat()` for easier state management** in UI.\
âœ” **Optimize prompts** to get better AI responses.

ðŸ“Œ **Example `.env.local` (DO NOT share this file)**

```sh
OPENAI_API_KEY=your-secret-api-key
```

***

### **8. Conclusion**

ðŸ”¥ **Vercel AI SDK + Next.js** makes AI integration super easy!\
ðŸ”¹ It **simplifies API calls**, **enables streaming**, and **optimizes performance**.\
ðŸ”¹ With **useChat() hook**, AI-powered apps become **faster and more interactive**.\
ðŸ”¹ **Perfect for chatbots, text generation, and AI-powered applications.**
